{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub update\n",
    "!git add . && git commit -m \"download and install list of stocks\" && git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equal-Weight S&P 500 Index Fund\n",
    "\n",
    "## Introduction & Library Imports\n",
    "\n",
    "The S&P 500 is the world's most popular stock market index. The largest fund that is benchmarked to this index is the SPDR® S&P 500® ETF Trust. It has more than US$250 billion of assets under management.\n",
    "\n",
    "The goal of this section of the course is to create a Python script that will accept the value of your portfolio and tell you how many shares of each S&P 500 constituent you should purchase to get an equal-weight version of the index fund.\n",
    "\n",
    "## Library Imports\n",
    "\n",
    "The first thing we need to do is import the open-source software libraries that we'll be using in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [227 lines of output]\n",
      "  <string>:460: UserWarning: Unrecognized setuptools command ('dist_info --output-dir C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-modern-metadata-sjfz7cm8 --keep-egg-info'), proceeding with generating Cython sources and expanding templates\n",
      "  Running from SciPy source directory.\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\libs', 'C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\libs', 'C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\lib']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable f77\n",
      "  customize IntelVisualFCompiler\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifl\n",
      "  customize AbsoftFCompiler\n",
      "  Could not locate executable f90\n",
      "  customize CompaqVisualFCompiler\n",
      "  Found executable C:\\Program Files\\Git\\usr\\bin\\DF.exe\n",
      "  Could not locate executable C:\\Program\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  Could not locate executable efl\n",
      "  customize Gnu95FCompiler\n",
      "  Found executable C:\\mingw64\\bin\\gfortran.exe\n",
      "  Using built-in specs.\n",
      "  COLLECT_GCC=C:\\mingw64\\bin\\gfortran.exe\n",
      "  COLLECT_LTO_WRAPPER=C:/mingw64/bin/../libexec/gcc/x86_64-w64-mingw32/8.1.0/lto-wrapper.exe\n",
      "  Target: x86_64-w64-mingw32\n",
      "  Configured with: ../../../src/gcc-8.1.0/configure --host=x86_64-w64-mingw32 --build=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --prefix=/mingw64 --with-sysroot=/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64 --enable-shared --enable-static --disable-multilib --enable-languages=c,c++,fortran,lto --enable-libstdcxx-time=yes --enable-threads=posix --enable-libgomp --enable-libatomic --enable-lto --enable-graphite --enable-checking=release --enable-fully-dynamic-string --enable-version-specific-runtime-libs --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-bootstrap --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-gnu-as --with-gnu-ld --with-arch=nocona --with-tune=core2 --with-libiconv --with-system-zlib --with-gmp=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-mpfr=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-mpc=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-isl=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-pkgversion='x86_64-posix-seh-rev0, Built by MinGW-W64 project' --with-bugurl=https://sourceforge.net/projects/mingw-w64 CFLAGS='-O2 -pipe -fno-ident -I/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/include -I/c/mingw810/prerequisites/x86_64-zlib-static/include -I/c/mingw810/prerequisites/x86_64-w64-mingw32-static/include' CXXFLAGS='-O2 -pipe -fno-ident -I/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/include -I/c/mingw810/prerequisites/x86_64-zlib-static/include -I/c/mingw810/prerequisites/x86_64-w64-mingw32-static/include' CPPFLAGS=' -I/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/include -I/c/mingw810/prerequisites/x86_64-zlib-static/include -I/c/mingw810/prerequisites/x86_64-w64-mingw32-static/include' LDFLAGS='-pipe -fno-ident -L/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/lib -L/c/mingw810/prerequisites/x86_64-zlib-static/lib -L/c/mingw810/prerequisites/x86_64-w64-mingw32-static/lib '\n",
      "  Thread model: posix\n",
      "  gcc version 8.1.0 (x86_64-posix-seh-rev0, Built by MinGW-W64 project)\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas,lapack not found in ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\libs', 'C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\lib']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  customize IntelVisualFCompiler\n",
      "  customize AbsoftFCompiler\n",
      "  customize CompaqVisualFCompiler\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  customize Gnu95FCompiler\n",
      "  Using built-in specs.\n",
      "  COLLECT_GCC=C:\\mingw64\\bin\\gfortran.exe\n",
      "  COLLECT_LTO_WRAPPER=C:/mingw64/bin/../libexec/gcc/x86_64-w64-mingw32/8.1.0/lto-wrapper.exe\n",
      "  Target: x86_64-w64-mingw32\n",
      "  Configured with: ../../../src/gcc-8.1.0/configure --host=x86_64-w64-mingw32 --build=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --prefix=/mingw64 --with-sysroot=/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64 --enable-shared --enable-static --disable-multilib --enable-languages=c,c++,fortran,lto --enable-libstdcxx-time=yes --enable-threads=posix --enable-libgomp --enable-libatomic --enable-lto --enable-graphite --enable-checking=release --enable-fully-dynamic-string --enable-version-specific-runtime-libs --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-bootstrap --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-gnu-as --with-gnu-ld --with-arch=nocona --with-tune=core2 --with-libiconv --with-system-zlib --with-gmp=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-mpfr=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-mpc=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-isl=/c/mingw810/prerequisites/x86_64-w64-mingw32-static --with-pkgversion='x86_64-posix-seh-rev0, Built by MinGW-W64 project' --with-bugurl=https://sourceforge.net/projects/mingw-w64 CFLAGS='-O2 -pipe -fno-ident -I/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/include -I/c/mingw810/prerequisites/x86_64-zlib-static/include -I/c/mingw810/prerequisites/x86_64-w64-mingw32-static/include' CXXFLAGS='-O2 -pipe -fno-ident -I/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/include -I/c/mingw810/prerequisites/x86_64-zlib-static/include -I/c/mingw810/prerequisites/x86_64-w64-mingw32-static/include' CPPFLAGS=' -I/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/include -I/c/mingw810/prerequisites/x86_64-zlib-static/include -I/c/mingw810/prerequisites/x86_64-w64-mingw32-static/include' LDFLAGS='-pipe -fno-ident -L/c/mingw810/x86_64-810-posix-seh-rt_v6-rev0/mingw64/opt/lib -L/c/mingw810/prerequisites/x86_64-zlib-static/lib -L/c/mingw810/prerequisites/x86_64-w64-mingw32-static/lib '\n",
      "  Thread model: posix\n",
      "  gcc version 8.1.0 (x86_64-posix-seh-rev0, Built by MinGW-W64 project)\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  flame_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries flame not found in ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\libs', 'C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\ProgramData\\Anaconda3\\Library\\lib\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack not found in ['C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\libs', 'C:\\\\ProgramData\\\\Anaconda3\\\\Library\\\\lib']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-ut_33ot4\\overlay\\Lib\\site-packages\\numpy\\distutils\\system_info.py:1712: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    if getattr(self, '_calc_info_{}'.format(lapack))():\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-ut_33ot4\\overlay\\Lib\\site-packages\\numpy\\distutils\\system_info.py:1712: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    if getattr(self, '_calc_info_{}'.format(lapack))():\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "      main()\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "      return hook(metadata_directory, config_settings)\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-ut_33ot4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 368, in prepare_metadata_for_build_wheel\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-ut_33ot4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 497, in run_setup\n",
      "      super().run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-ut_33ot4\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 313, in run_setup\n",
      "      exec(code, locals())\n",
      "    File \"<string>\", line 583, in <module>\n",
      "    File \"<string>\", line 579, in setup_package\n",
      "    File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-build-env-ut_33ot4\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 137, in setup\n",
      "      config = configuration()\n",
      "    File \"<string>\", line 477, in configuration\n",
      "  numpy.distutils.system_info.NotFoundError: No lapack/blas resources found.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter==1.0.0 (from -r requirements.txt (line 1))Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Collecting jupyter-client==6.1.3 (from -r requirements.txt (line 2))\n",
      "  Using cached jupyter_client-6.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jupyter-console==6.1.0 (from -r requirements.txt (line 3))\n",
      "  Using cached jupyter_console-6.1.0-py2.py3-none-any.whl.metadata (951 bytes)\n",
      "Collecting jupyter-core==4.6.3 (from -r requirements.txt (line 4))\n",
      "  Using cached jupyter_core-4.6.3-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting numpy==1.17.4 (from -r requirements.txt (line 5))\n",
      "  Using cached numpy-1.17.4-cp39-cp39-win_amd64.whl\n",
      "Collecting pandas==0.25.3 (from -r requirements.txt (line 6))\n",
      "  Using cached pandas-0.25.3.tar.gz (12.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting requests==2.22.0 (from -r requirements.txt (line 7))\n",
      "  Using cached requests-2.22.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting scipy==1.5.2 (from -r requirements.txt (line 8))\n",
      "  Using cached scipy-1.5.2.tar.gz (25.4 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade numpy\n",
    "# %pip uninstall numpy\n",
    "# %pip install -r requirements.txt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests  # HTTP Requests for API interaction\n",
    "import xlsxwriter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Our List of Stocks\n",
    "\n",
    "The next thing we need to do is import the constituents of the S&P 500.\n",
    "\n",
    "These constituents change over time, so in an ideal world you would connect directly to the index provider (Standard & Poor's) and pull their real-time constituents on a regular basis.\n",
    "\n",
    "Paying for access to the index provider's API is outside of the scope of this course. \n",
    "\n",
    "There's a static version of the S&P 500 constituents available here. [Click this link to download them now](https://drive.google.com/file/d/1ZJSpbY69DVckVZlO9cC6KkgfSufybcHN/view?usp=sharing). Move this file into the `starter-files` folder so it can be accessed by other files in that directory.\n",
    "\n",
    "Now it's time to import these stocks to our Jupyter Notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZBRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>ZION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker\n",
       "0        A\n",
       "1      AAL\n",
       "2      AAP\n",
       "3     AAPL\n",
       "4     ABBV\n",
       "..     ...\n",
       "500    YUM\n",
       "501    ZBH\n",
       "502   ZBRA\n",
       "503   ZION\n",
       "504    ZTS\n",
       "\n",
       "[505 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = pd.read_csv('sp_500_stocks.csv')\n",
    "type(stocks)\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring an API Token\n",
    "\n",
    "Now it's time to import our IEX Cloud API token. This is the data provider that we will be using throughout this course.\n",
    "\n",
    "API tokens (and other sensitive information) should be stored in a `secrets.py` file that doesn't get pushed to your local Git repository. We'll be using a sandbox API token in this course, which means that the data we'll use is randomly-generated and (more importantly) has no cost associated with it.\n",
    "\n",
    "[Click here](http://nickmccullum.com/algorithmic-trading-python/secrets.py) to download your `secrets.py` file. Move the file into the same directory as this Jupyter Notebook before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets_0x01 import IEX_CLOUD_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Our First API Call\n",
    "\n",
    "Now it's time to structure our API calls to IEX cloud. \n",
    "\n",
    "We need the following information from the API:\n",
    "\n",
    "* Market capitalization for each stock\n",
    "* Price of each stock\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sandbox.iexapis.com/stable/stock/AAPL/quote/?token=Tpk_059b97af715d417d9f49f50b51b1c448\n",
      "<Response [403]>\n"
     ]
    }
   ],
   "source": [
    "symbol = 'AAPL'\n",
    "api_url = f'https://sandbox.iexapis.com/stable/stock/{symbol}/quote/?token={IEX_CLOUD_API_TOKEN}'\n",
    "print(api_url)\n",
    "data = requests.get(api_url)\n",
    "# data = requests.get(api_url).json()\n",
    "# print(data.status_code)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Our API Call\n",
    "\n",
    "The API call that we executed in the last code block contains all of the information required to build our equal-weight S&P 500 strategy. \n",
    "\n",
    "With that said, the data isn't in a proper format yet. We need to parse it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Our Stocks Data to a Pandas DataFrame\n",
    "\n",
    "The next thing we need to do is add our stock's price and market capitalization to a pandas DataFrame. Think of a DataFrame like the Python version of a spreadsheet. It stores tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping Through The Tickers in Our List of Stocks\n",
    "\n",
    "Using the same logic that we outlined above, we can pull data for all S&P 500 stocks and store their data in the DataFrame using a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Batch API Calls to Improve Performance\n",
    "\n",
    "Batch API calls are one of the easiest ways to improve the performance of your code.\n",
    "\n",
    "This is because HTTP requests are typically one of the slowest components of a script.\n",
    "\n",
    "Also, API providers will often give you discounted rates for using batch API calls since they are easier for the API provider to respond to.\n",
    "\n",
    "IEX Cloud limits their batch API calls to 100 tickers per request. Still, this reduces the number of API calls we'll make in this section from 500 to 5 - huge improvement! In this section, we'll split our list of stocks into groups of 100 and then make a batch API call for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Number of Shares to Buy\n",
    "\n",
    "As you can see in the DataFrame above, we stil haven't calculated the number of shares of each stock to buy.\n",
    "\n",
    "We'll do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Our Excel Output\n",
    "\n",
    "We will be using the XlsxWriter library for Python to create nicely-formatted Excel files.\n",
    "\n",
    "XlsxWriter is an excellent package and offers tons of customization. However, the tradeoff for this is that the library can seem very complicated to new users. Accordingly, this section will be fairly long because I want to do a good job of explaining how XlsxWriter works.\n",
    "\n",
    "### Initializing our XlsxWriter Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Formats We'll Need For Our `.xlsx` File\n",
    "\n",
    "Formats include colors, fonts, and also symbols like `%` and `$`. We'll need four main formats for our Excel document:\n",
    "* String format for tickers\n",
    "* \\\\$XX.XX format for stock prices\n",
    "* \\\\$XX,XXX format for market capitalization\n",
    "* Integer format for the number of shares to purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the Formats to the Columns of Our `.xlsx` File\n",
    "\n",
    "We can use the `set_column` method applied to the `writer.sheets['Recommended Trades']` object to apply formats to specific columns of our spreadsheets.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```python\n",
    "writer.sheets['Recommended Trades'].set_column('B:B', #This tells the method to apply the format to column B\n",
    "                     18, #This tells the method to apply a column width of 18 pixels\n",
    "                     string_template #This applies the format 'string_template' to the column\n",
    "                    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code works, but it violates the software principle of \"Don't Repeat Yourself\". \n",
    "\n",
    "Let's simplify this by putting it in 2 loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Our Excel Output\n",
    "\n",
    "Saving our Excel file is very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
